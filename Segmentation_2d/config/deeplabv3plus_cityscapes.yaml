class_num: &class_num 19
ignore_index: &ignore_index 19
root: "Segmentation_2d/DeepLabV3"
task: &task "semseg"

img_mean: &img_mean [0.485, 0.456, 0.406]
img_std: &img_std [0.229, 0.224, 0.225]
dataset_name: &dataset_name "CityScapes"

data_path: "Dataset/cityscapes/"
meta_path: "Dataset/cityscapes/meta"
train_batch_size: 8
val_batch_size: 4
test_batch_size: 4

transforms:
  train:
    - type: RandomCrop
      crop_size: [512, 1024]
    - type: ColorJitter
      brightness: 0.5
      contrast: 0.5
      saturation: 0.5
    - type: RandomHorizontalFlip
      prob: 0.5
    - type: ToTensor
    - type: Normalize
      mean: *img_mean
      std: *img_std
  val:
    - type: Resize
      size: [512, 1024]
    - type: CenterCrop
      crop_size: [512, 1024]
    - type: ToTensor
    - type: Normalize
      mean: *img_mean
      std: *img_std
  test:
    - type: Resize
      size: [512, 1024]
    - type: CenterCrop
      crop_size: [512, 1024]
    - type: ToTensor
    - type: Normalize
      mean: *img_mean
      std: *img_std

model:
  name: "DeepLabV3Plus"
  backbone: "resnet101"
  class_num: *class_num
  in_channel: 2048
  bn_momentum: 0.1
  weight_init: "xavier"

# Training
epochs: 100
scheduler:
  name: "Poly"
  max_iters: 90000

optimizer:
  name: "SGD"
  weight_decay: 0.0001
  momentum: 0.9
  lr: 0.01

loss:
  name: CrossEntropyLoss
  ignore_index: *ignore_index
  lovasz_weight: 1.5
  boundary_weight: 0.5

metrics:
  name: "ConfusionMatrix"
  task: *task
  class_num: *class_num
  ignore_index: *ignore_index

visualizer:
  name: "ImageSegVisualizer"
  dataset_name: *dataset_name
  mean: *img_mean
  std: *img_std